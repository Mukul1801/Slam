import openai
from langchain.agents import create_sql_agent
from langchain_community.agent_toolkits.sql.toolkit import SQLDatabaseToolkit
from langchain.sql_database import SQLDatabase
from azure.identity import DefaultAzureCredential, get_bearer_token_provider
from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings
from openai import AzureOpenAI
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder

import numpy as np
import faiss

HOST = SERVER_NAME+'/'+HOST_HTTP_PATH

db = SQLDatabase.from_databricks(catalog=database, schema="abc", engine_args={"pool_pre_ping": True},host=HOST,api_token=DATABRICKS_TOKEN,warehouse_id=warehouse_id)

IGNORED_COLUMNS = {
    "#", "Detailed Table Information", "Catalog", "Database", "Table",
    "Created Time", "Last Access", "Created By", "Type", "Location",
    "Provider", "Owner", "Is_managed_location", "Predictive Optimization", "Table Properties"
}

def extract_table_metadata(table_name):
    """Retrieves table metadata and formats it properly."""
    try:
        describe_output = db.run(f"DESCRIBE EXTENDED {table_name}")
        processed_output = eval(describe_output) if isinstance(describe_output, str) else describe_output
    except Exception as e:
        return {"table_name": table_name, "description": f"Error retrieving metadata: {str(e)}", "columns": []}

    column_details = []
    table_description = "No description available"

    for row in processed_output:
        if row[0].strip().lower() == "comment":
            table_description = row[1]  # Extract table description
        elif len(row) == 3 and row[0].strip() and row[0].strip() not in IGNORED_COLUMNS:
            column_details.append({
                "name": row[0], 
                "type": row[1], 
                "description": row[2] or "No description available"
            })

    return {
        "table_name": table_name,
        "description": table_description,
        "columns": column_details
    }

tables = db.get_usable_table_names()
table_metadata=[]
for table in tables:
    table_metadata.append(extract_table_metadata(table))

def clean_metadata(table_metadata):
    for table in table_metadata:
        table["columns"] = [
            col for col in table["columns"] if col["name"].strip() and col["name"] != "# Detailed Table Information"
        ]
    return table_metadata

clean_metadata = clean_metadata(table_metadata)

# Define the required scope
scope = "jkl"

# Initialize the credential
credential = DefaultAzureCredential()

token_provider = get_bearer_token_provider(credential, scope)

# Ensure you request a token with the correct scope
token = credential.get_token(scope)

client = openai.AzureOpenAI(
    api_version="ghi",
    azure_endpoint="def",
    azure_ad_token_provider=token_provider
)

embedding_model = AzureOpenAIEmbeddings(
    azure_deployment="text-embedding-ada-002",  # Set the correct Azure deployment name
    azure_endpoint="def",
    api_version="ghi",
    azure_ad_token_provider=token_provider
)

llm_instance = AzureChatOpenAI(
    azure_deployment="gpt-4o-mini",# "gpt-4o-mini", #"gpt-35-turbo",  # or your deployment
    api_version= "ghi",  # or your api version
    temperature=0,
    #seed = 0,
    max_tokens=None,
    #model_version="2024-07-18",
    timeout=None,
    max_retries=5,
    verbose=True,
    azure_endpoint = def",
    azure_ad_token_provider=token_provider
)

def get_embeddings(text):
    token_provider = get_bearer_token_provider(
    DefaultAzureCredential(), "jkl"
    )

    client = AzureOpenAI(
        api_version="ghi",
        azure_endpoint="def",
        azure_ad_token_provider=token_provider
    )
    response = client.embeddings.create(
        model="text-embedding-ada-002",
        input=text
    )
    return response.data[0].embedding

# Convert each table's metadata into a structured text format
table_texts = [
    f"Table: {table['table_name']}\nDescription: {table['description']}\nColumns: {table['columns']}"
    for table in clean_metadata
]

embeddings = np.array([get_embeddings(text) for text in table_texts])

dimension = embeddings.shape[1]  # Get embedding dimension
index = faiss.IndexFlatL2(dimension)
index.add(embeddings)

def query_faiss(query_text):
    """Uses FAISS to find relevant tables based on query embeddings."""
    query_embedding = np.array(get_embeddings(query_text)).reshape(1, -1).astype("float32")

    # Retrieve top-k relevant tables
    k = 3
    distances, indices = index.search(query_embedding, k)

    relevant_table_metadata = [clean_metadata[i] for i in indices[0]]  # Direct lookup

    # Format extracted metadata for readability
    formatted_metadata = "\n\n".join(
        f"**Table:** {table['table_name']}\n**Description:** {table['description']}\n**Columns:**\n" +
        "\n".join([f"- {col['name']} ({col['type']}): {col['description']}" for col in table["columns"]])
        for table in relevant_table_metadata
    )

    return formatted_metadata

class PromptTemplate():
    def __init__(self) -> None:
        pass

    string_template = """
            You are a helpful AI assistant expert in querying SQL Databases to find answers to the user's questions. \
        Given an input question, first create a syntactically correct {dialect} SQL query to run, then look at the results of the query and provide a meaningful, human-readable answer to the input question. \
        Do not return the raw SQL query result directly as the final answer. Instead, interpret the result and explain it in a concise and clear manner. \
        You can order the results by a relevant column to return the most interesting examples in the database. \
        Unless otherwise specified, do not return more than {top_k} rows.\
        Do not try to pull table information from database and only use the table_info provided.\
 
        ===Response Guidelines
        1. Follow these instructions for creating syntactically correct SQL queries: \
            - Be sure not to query for columns that do not exist in the tables and use alias only where required.\
            - Include unit_name, plant_name, actual_energy, daily_target_volume, and equipment_name in query if mentioned.\
            - Always use the column 'unit_name' associated with the unit in the generated query.\
            - Always use the column 'plant_name' in sql query generation whenever asked for plant or plant Names in user query. \
            - Always use the column 'actual_energy' associated with the energy consumption in the generated query.\
            - Always use the column 'daily_target_volume' associated with the production target, target volumne in the generated query.\
            - Always use the column 'unit_name' associated with the unit name [('Ammonia-Y1',), ('Urea-Y4',), ('Urea-Y2',), ('Mine-8',), ('Urea-Y1',), ('LNG-7',), ('Urea-Y3',), ('LNG-5',), ('Ammonia-Y3',), ('Ammonia-Y2',), ('Ammonia-Y4',), ('LNG-6',)] .\
            - Always use the column 'plant_name' associated with the plant name [('Y2',), ('Y3',), ('Y4',), ('Y1',)]. \
            - Always use the column 'equipment_name' associated with the Asset in the generated query.\
            - Whenever asked for plant or plant Names, return the institute names using column 'plant_name' associated with the 'plant_name' in the generated query.\
            - Likewise, Use appropriate aggregation functions (AVG, SUM). Use'AVG' when average word, 'SUM' when total or overall word is used. Else DO NOT use aggregate functions.\
            - Pay close attention to the filtering criteria mentioned in the question and incorporate them using the WHERE clause in your SQL query.\
            - If the question involves multiple conditions, use logical operators such as AND, OR to combine them effectively.\
            - When dealing with date or timestamp columns, use appropriate date functions (e.g., DATE_PART, EXTRACT) for extracting specific parts of the date or performing date arithmetic.\
            - If the question involves grouping of data (e.g., finding totals or averages for different categories), use the GROUP BY clause along with appropriate aggregate functions.\
            - Consider using aliases for tables and columns to improve readability of the query, especially in case of complex joins or subqueries.\
            - If necessary, use subqueries or common table expressions (CTEs) to break down the problem into smaller, more manageable parts. \
            - To determine the most energy-efficient or energy-inefficient plant, calculate the ratio by dividing the sum of actual production volume by the sum of actual energy used. Display the result and group along with plant namev only and unit if required. Do not apply the HAVING clause in the query.\
            - Incorporate filtering criteria using the WHERE clause.\
            - Use date functions for date or timestamp columns.\
 
        2. After executing the SQL query, interpret the results and provide a meaningful, human-readable answer to the user's question. \
            - For example, if the query returns a numeric value, explain what it represents. \
            - If the query returns multiple rows, summarize the key insights instead of listing all rows. \
            - If the query involves trends or comparisons, describe them clearly.
 
        3. If the provided context is insufficient, explain why the query cannot be generated or why the question cannot be answered.
 
        4. Always format the SQL query for readability before responding.
 
        5. Always respond with a valid, well-formed JSON object in the following format:
        {{
            "SQLQuery": "Generated SQL query here",
            "SQLResult": "Raw SQL query result here",
            "Answer": "Human-readable interpretation of the result here"
        }}
       
        6. If the user query is about creating graphs or plots, generate a valid SQL query to produce the data required for plotting and explain how the data can be visualized.
 
        7. If you do not know the answer, reply as follows: {{"answer": "I do not know."}}

        8. Remove sql keyword from query generated. 
 
        ===Response Format
        You are required to use the following format, each taking one line:
 
        Question: Question here
        SQLQuery: SQL Query to run
        SQLResult: Result of the SQLQuery
        Answer: A detailed, human-readable final answer here
        """


    def define_prompt(self,template, table_info):

        prompt = ChatPromptTemplate.from_messages(
                [
                    ("system", template),
                    ("human", "Use this table info only: {table_info}"),
                    ("human", "{input}"),
                    MessagesPlaceholder(variable_name="agent_scratchpad"),
                ]
            )
        return prompt

toolkit = SQLDatabaseToolkit(db=db, llm=llm_instance)
def agent_trigger(question):
    # Define your prompt template
    #prompt_templates = PromptTemplate()

    context = query_faiss(question)

    #string_prompt = prompt_templates.define_prompt(prompt_templates.string_template, context)
    # Create prompt using the provided template
    string_prompt = define_prompt(PromptTemplate.string_template, context)

    dbr_agent = create_sql_agent(
        llm=llm_instance,
        toolkit=toolkit,
        prompt=string_prompt,
        agent_type= "openai-tools",
        handle_parsing_errors=True,
        verbose=False
        )
    
    human_response = dbr_agent.invoke({
        "dialect":db.dialect,
        "table_info": context,
        "top_k":3,
        "agent_scratchpad":[],
        "input": question
    })
    return (human_response)
